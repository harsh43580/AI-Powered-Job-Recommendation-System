

## ğŸ§  **Project: AI-Powered Job Recommendation System**

---

### ğŸ¯ **Objective**
Build  tool that:
- Lets users upload their resume
- Matches it to the top 10 most relevant job descriptions (JDs)
- Shows matching percentage and missing skills for each job

---

## ğŸ”§ **System Components & Tools**

| Layer          | Technology       | Purpose |
|----------------|------------------|---------|
| **Frontend**   | Streamlit        | UI for uploading resume and displaying results |
| **Backend / Logic** | Python + HuggingFace Transformers | Embedding generation & skill analysis |
| **Vector Database** | Qdrant (local via Docker) | Store and search resume embeddings |
| **Job Data Source** | In-memory list or JSON file | Store JD texts + (optional) cached embeddings |
| **Embedding Model** | `all-MiniLM-L6-v2` (SentenceTransformers) | Generate text embeddings |
| **Skill Extraction** | spaCy or keyword extraction | Identify matched and missing skills |

---

## ğŸ“ **Workflow Breakdown**

### ğŸ”¹ 1. Resume Upload
- User uploads PDF in Streamlit
- Text is parsed using:
  - `PyPDF2` if it's a text-based PDF
  - `pytesseract + pdf2image` if it's image-based
- Cleaned text is hashed (`SHA-256`) to prevent duplicates

### ğŸ”¹ 2. Resume Embedding + Storage
- If hash not already in Qdrant:
  - Generate embedding using SentenceTransformer
  - Store in Qdrant with payload (`user_id`, `hash`, `timestamp`)
- If already present:
  - Reuse existing vector (skip re-upload)

### ğŸ”¹ 3. JD Matching
- Use list of job descriptions (in code or from JSON)
- Optionally pre-embed JDs and cache them
- For each JD:
  - Compute cosine similarity with resume embedding
  - Extract overlapping and missing skills
  - Calculate a **match score**:
    ```
    match_score = 0.7 * cosine_similarity + 0.3 * skill_match_ratio
    ```

### ğŸ”¹ 4. Display Top 10 Matches
- Show job title, score (%), and missing skills
- Optional: Add charts or interactivity for skills visualization

---

## ğŸ›¡ï¸ **Optimizations & Best Practices**

| Concern         | Solution |
|------------------|----------|
| Duplicate resumes | Hash text content before storing |
| Performance with many JDs | Cache JD embeddings |
| Skill clarity | Use noun phrase extraction or skill keywords |
| User preferences | Add filters in Streamlit (`role`, `location`, `skills`) |
| Scalable Search | Switch to vector DB for JDs if they grow large |

---

## âœ¨ Optional Future Add-ons
- Save user sessions or results
- User feedback loop (â€œWas this job relevant?â€)
- Personalized job learning paths (from missing skills)
- Filter by industry, experience level, or remote/onsite
- Add `pgvector` or `Qdrant cloud` for production-scale

---

## ğŸ Final Architecture Snapshot (Local Dev)

```plaintext
[ Streamlit Frontend ]
        â”‚
        â–¼
[ Resume Upload & Parse ]
        â”‚
        â–¼
[ Hash + Embed + Store in Qdrant ]
        â”‚
        â–¼
[ Compare to Local JD List (embedded) ]
        â”‚
        â–¼
[ Match %, Missing Skills, Rank Top 10 ]
        â”‚
        â–¼
[ Display Results to User (Interactive) ]
```

---

## âœ… Summary: MVP Goals â€” All Covered
- âœ”ï¸ Resume-based job recommendations
- âœ”ï¸ Matching % + missing skills
- âœ”ï¸ Lightweight vector DB with deduplication
- âœ”ï¸ No unnecessary overhead

---

Would you like a `starter repo scaffold` with:
- Docker Qdrant setup
- Streamlit starter app
- Resume parser + deduplicator
- Matching engine?
```
job_recommender/
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ data/
â”‚   â””â”€â”€ job_listings.json   # Sample JDs
â”œâ”€â”€ resumes/
â”‚   â””â”€â”€ (uploaded resumes)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ parser.py           # Resume parsing (PDF + OCR)
â”‚   â”œâ”€â”€ embeddings.py       # Embedding + hashing logic
â”‚   â”œâ”€â”€ jobs.py             # JD handling, embedding
â”‚   â”œâ”€â”€ matcher.py          # Matching + scoring
â”‚   â””â”€â”€ qdrant_client.py    # Qdrant connection helpers
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ jd_embeddings.pkl   # Cached JD embeddings (optional)
â””â”€â”€ requirements.txt        # Dependencies
```